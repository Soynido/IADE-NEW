# IADE NEW ‚Äî Liste des T√¢ches Actionnables v1.1

**Document de r√©f√©rence** : 106 t√¢ches organis√©es par 10 phases

Date : 5 novembre 2025  
Version : 1.0  
Statut : Pr√™t pour ex√©cution

---

## Format Standard des T√¢ches

```
[NUMERO] [STATUT] Titre de la t√¢che
  Description : ...
  D√©pendances : ...
  Fichiers concern√©s : ...
  Crit√®res de validation : ...
  Estimation : ...
```

**Statuts** : `TODO` | `IN PROGRESS` | `DONE` | `BLOCKED`

**R√®gle fondamentale** : 1 commit = 1 t√¢che. Apr√®s chaque t√¢che `DONE`, marquer comme telle et commit.

---

## Phase 0 : Setup & Infrastructure (J1-J2)

### [001] TODO Initialiser la structure de dossiers du projet

**Description** : cr√©er l'arborescence compl√®te du projet : `src/`, `scripts/`, `venv/`, `tests/`, `docs/`, sous-dossiers (`components/`, `data/`, `store/`, `utils/`, `ai_generation/`, `reports/`)

**D√©pendances** : aucune

**Fichiers concern√©s** :
- Structure compl√®te du projet

**Crit√®res de validation** :
- Tous les dossiers pr√©sents et vides
- Structure conforme √† spec.md Section I

**Estimation** : 15 min

---

### [002] TODO Configurer Vite + React + Tailwind

**Description** : initialiser projet Vite avec template React + TypeScript, installer Tailwind CSS, configurer `tailwind.config.js`

**D√©pendances** : [001]

**Fichiers concern√©s** :
- `package.json`
- `vite.config.ts`
- `tailwind.config.js`
- `src/index.css`

**Crit√®res de validation** :
- `npm run dev` d√©marre sans erreur
- Page blanche avec styles Tailwind fonctionnels

**Estimation** : 30 min

---

### [003] TODO Configurer environnement Python 3.13

**Description** : cr√©er venv, installer d√©pendances (PyPDF2, transformers, torch, ollama-python, scikit-learn, sentence-transformers)

**D√©pendances** : [001]

**Fichiers concern√©s** :
- `requirements.txt`
- `venv/`

**Crit√®res de validation** :
- `python --version` = 3.13.x
- `pip list` montre toutes d√©pendances install√©es

**Estimation** : 20 min

---

### [004] TODO Installer et tester Ollama + Mistral 7B

**Description** : installer Ollama localement, pull `mistral:latest`, cr√©er script test g√©n√©ration QCM simple

**D√©pendances** : [003]

**Fichiers concern√©s** :
- `scripts/test_ollama.py`

**Crit√®res de validation** :
- `ollama list` montre `mistral:latest`
- `python scripts/test_ollama.py` g√©n√®re un QCM test valide (JSON parsable)

**Estimation** : 45 min

---

### [005] TODO Installer et tester BioBERT

**Description** : installer pipeline HuggingFace, t√©l√©charger `dmis-lab/biobert-base-cased-v1.1`, cr√©er script test calcul embedding + score

**D√©pendances** : [003]

**Fichiers concern√©s** :
- `scripts/test_biobert.py`

**Crit√®res de validation** :
- BioBERT mod√®le t√©l√©charg√© dans cache HuggingFace
- `python scripts/test_biobert.py` calcule score biom√©dical sur texte m√©dical test (score ‚àà [0,1])

**Estimation** : 30 min

---

## Phase 1 : Extraction PDF (J3-J5)

### [010] TODO D√©velopper extract_pdfs.py ‚Äî d√©tection titres

**Description** : impl√©menter heuristiques de d√©tection titres : regex hi√©rarchie (`^\d+\.`, `^CHAPITRE`, `^\p{Lu}{3,}`), d√©tection majuscules + contexte, sauts de pages + densit√© mots-cl√©s

**D√©pendances** : [003]

**Fichiers concern√©s** :
- `scripts/extract_pdfs.py`

**Crit√®res de validation** :
- Test sur PDF √©chantillon (5 pages) d√©tecte au moins 2 titres
- Sortie JSON contient sections avec `title`, `pages`

**Estimation** : 2h

---

### [011] TODO D√©velopper extract_pdfs.py ‚Äî d√©coupage chunks

**Description** : impl√©menter d√©coupage en chunks (< 1200 tokens), fen√™tres s√©mantiques, normalisation (suppression en-t√™tes/pieds), g√©n√©ration `chunk_id` unique

**D√©pendances** : [010]

**Fichiers concern√©s** :
- `scripts/extract_pdfs.py`

**Crit√®res de validation** :
- Chunks g√©n√©r√©s ont `chunk_id`, `text`, `token_count < 1200`
- Aucun chunk vide
- `chunk_id` unique : `{module_id}_{section_id}_c{num}`

**Estimation** : 2h

---

### [012] TODO Ex√©cuter extraction sur les 3 PDF

**Description** : lancer `extract_pdfs.py` sur `Prepaconcoursiade-Complet.pdf`, `annalescorrig√©es-Volume-1.pdf`, `annalescorrig√©es-Volume-2.pdf`

**D√©pendances** : [011]

**Fichiers concern√©s** :
- `src/data/modules/*.json` (g√©n√©r√©s)

**Crit√®res de validation** :
- ‚â• 12 modules g√©n√©r√©s
- Chaque module a `sections` + `chunks` valides
- Total chunks ‚â• 500

**Estimation** : 1h (+ 2h temps machine)

---

### [013] TODO G√©n√©rer metadata.json initial

**Description** : mapper sources ‚Üí types (cours/annales), liste modules d√©tect√©s, pages extraites/totales

**D√©pendances** : [012]

**Fichiers concern√©s** :
- `src/data/metadata.json`

**Crit√®res de validation** :
- Fichier conforme au sch√©ma (spec.md Section III)
- Champs : `sources`, `modules`, `extraction_date`, `total_pages`, `total_chunks`

**Estimation** : 30 min

---

### [014] TODO Validation manuelle taxonomie et overrides

**Description** : revue manuelle modules g√©n√©r√©s, ajustements dans `metadata.json` (`module_map_overrides` si n√©cessaire), v√©rification couverture chapitres

**D√©pendances** : [013]

**Fichiers concern√©s** :
- `src/data/metadata.json`

**Crit√®res de validation** :
- Couverture ‚â• 70% des chapitres attendus (cf. spec.md Section II)
- Modules renomm√©s si n√©cessaire (overrides)
- Documentation ajustements dans commit message

**Estimation** : 1h

---

## Phase 2 : Indexation & Alignement (J6-J7)

### [018] TODO Cr√©er script index_chunks.py ‚Äî extraction TF-IDF keywords

**Description** : impl√©menter extraction TF-IDF par chunk (`TfidfVectorizer(max_features=50, ngram_range=(1,2))`), top 10 mots-cl√©s par chunk, agr√©gation par module

**D√©pendances** : [014]

**Fichiers concern√©s** :
- `scripts/index_chunks.py`

**Crit√®res de validation** :
- Script ex√©cutable, sortie `keywords.json` conforme sch√©ma
- Test sur 1 module : g√©n√®re ‚â• 3 mots-cl√©s/chunk

**Estimation** : 2h

---

### [019] TODO Ex√©cuter indexation compl√®te

**Description** : lancer `index_chunks.py` sur tous les modules

**D√©pendances** : [018]

**Fichiers concern√©s** :
- `src/data/keywords.json`

**Crit√®res de validation** :
- ‚â• 80% chunks avec ‚â• 3 mots-cl√©s pertinents
- Mots-cl√©s m√©dicaux identifiables (PEEP, morphine, PIC, etc.)

**Estimation** : 30 min

---

### [024] TODO Cr√©er script analyze_annales.py ‚Äî analyse des annales

**Description** : parser annales PDF (Volumes 1 & 2), extraire longueur moyenne √©nonc√©s, structure syntaxique r√©currente (d√©buts phrases), pond√©ration modules (fr√©quence)

**D√©pendances** : [014]

**Fichiers concern√©s** :
- `scripts/analyze_annales.py`

**Crit√®res de validation** :
- Script parse les 2 volumes sans erreur
- Sortie JSON contient : `avg_question_length`, `common_starters`, `module_weights`

**Estimation** : 2h

---

### [025] TODO Ex√©cuter analyse des 2 volumes d'annales

**Description** : lancer `analyze_annales.py` sur `annalescorrig√©es-Volume-1.pdf` et `annalescorrig√©es-Volume-2.pdf`

**D√©pendances** : [024]

**Fichiers concern√©s** :
- `src/data/annales_profile.json`

**Crit√®res de validation** :
- Fichier g√©n√©r√© conforme sch√©ma (spec.md Section II)
- Longueur moyenne ‚àà [70, 120] caract√®res
- Module weights coh√©rents (cardio + pharma + respiratoire ‚â• 60%)

**Estimation** : 30 min

---

### [024b] TODO Cr√©er script stylistic_validator.py

**Description** : impl√©menter mesure distance stylistique : Levenshtein normalis√© + similarit√© phrastique (sentence-transformers `all-MiniLM-L6-v2`)

**D√©pendances** : [025]

**Fichiers concern√©s** :
- `scripts/reports/stylistic_validator.py`

**Crit√®res de validation** :
- Script ex√©cutable
- Test sur √©chantillon : calcule distance ‚àà [0,1]

**Estimation** : 2h

---

### [025b] TODO Configurer seuils BioBERT adaptatifs par module

**Description** : ajouter `biomedical_thresholds` dans `metadata.json` (pharma: 0.08-0.10, cardio: 0.06, respiratoire: 0.05, etc.)

**D√©pendances** : [025]

**Fichiers concern√©s** :
- `src/data/metadata.json`

**Crit√®res de validation** :
- Champ `biomedical_thresholds` pr√©sent avec 17 modules
- Seuils coh√©rents avec spec.md Section II (tableau)

**Estimation** : 30 min

---

## Phase 3 : G√©n√©ration QCM (J8-J10)

### [020] TODO D√©velopper generate_batch.py ‚Äî prompt engineering

**Description** : cr√©er prompts syst√®me et user pour Mistral, injection chunk/module/keywords/annales_profile, formatter JSON strict

**D√©pendances** : [019], [025]

**Fichiers concern√©s** :
- `scripts/ai_generation/generate_batch.py`

**Crit√®res de validation** :
- G√©n√©ration manuelle sur 1 chunk produit JSON parsable
- JSON contient : `text`, `options[4]`, `correctAnswer`, `explanation`, `source_context`

**Estimation** : 1h30

---

### [021] TODO D√©velopper generate_batch.py ‚Äî parsing JSON

**Description** : parser r√©ponse Mistral (JSON array), gestion erreurs format (retry max 3√ó, fallback), logging erreurs

**D√©pendances** : [020]

**Fichiers concern√©s** :
- `scripts/ai_generation/generate_batch.py`

**Crit√®res de validation** :
- Parsing sur 10 chunks test : taux succ√®s ‚â• 80%
- Erreurs logg√©es avec chunk_id et raison

**Estimation** : 1h

---

### [022] TODO D√©velopper generate_batch.py ‚Äî batch processing

**Description** : boucle sur modules/chunks, logs progression (tqdm), gestion erreurs et retry (max 3 tentatives), sauvegarde incr√©mentale

**D√©pendances** : [021]

**Fichiers concern√©s** :
- `scripts/ai_generation/generate_batch.py`

**Crit√®res de validation** :
- G√©n√©ration sur 1 module complet (respiratoire) : ‚â• 100 questions
- Logs montrent progression chunk par chunk
- Fichier sortie valide apr√®s interruption + reprise

**Estimation** : 2h

---

### [023] IN PROGRESS Ex√©cuter g√©n√©ration batch compl√®te (OPTIMIS√âE)

**Description** : lancer `generate_batch.py` sur tous les modules avec PARALL√âLISATION (4 workers), monitoring erreurs, sauvegarde logs + progression temps r√©el

**OPTIMISATIONS APPLIQU√âES** :
- ‚ö° Parall√©lisation : 4 workers simultan√©s (√ó4 vitesse)
- üìâ 2 QCM/chunk au lieu de 3 (‚Üì33% temps)
- üìä Fichier progression JSON (logs/generation_progress.json)
- üîÑ Monitoring temps r√©el avec refresh auto (5 sec)

**D√©pendances** : [022]

**Fichiers concern√©s** :
- `src/data/questions/generated_raw.json`
- `logs/generation_batch.log`
- `logs/generation_progress.json` (nouveau)

**Crit√®res de validation** :
- ‚â• 2000 questions g√©n√©r√©es (cible: 2500)
- Taux succ√®s global > 85%
- Logs montrent r√©partition par module

**Estimation** : 6-8h au lieu de 25h (r√©duction ~70% gr√¢ce √† parall√©lisation)

**Monitoring** :
```bash
# Terminal d√©di√© : monitoring avec refresh auto (5 sec)
bash scripts/monitor_generation.sh

# Alternative : logs bruts
tail -f logs/generation_batch.log

# V√©rification JSON
cat logs/generation_progress.json | jq .
```

**Statut** : üîÑ EN COURS (d√©marr√© 16:24, ETA ~6-8h)

---

### [023b] TODO Ex√©cuter feedback it√©ratif stylistique

**Description** : apr√®s g√©n√©ration, mesurer distance stylistique vs annales, ajuster prompts si distance > 0.35, re-g√©n√©rer √©chantillon, converger < 0.3

**D√©pendances** : [023], [024b]

**Fichiers concern√©s** :
- `scripts/ai_generation/generate_batch.py` (ajustement prompts)
- `src/data/style_calibration_log.json`

**Crit√®res de validation** :
- Distance stylistique moyenne < 0.3 apr√®s ajustements
- Logs montrent it√©rations (max 3)

**Estimation** : 2h

---

## Phase 4 : Validation Double (J11-J13)

### [030] TODO D√©velopper biobert_client.py ‚Äî embeddings

**Description** : pipeline HuggingFace BioBERT, fonction embedding `question + explanation`, cache embeddings

**D√©pendances** : [005]

**Fichiers concern√©s** :
- `scripts/ai_generation/biobert_client.py`

**Crit√®res de validation** :
- Embeddings sur 10 questions test : vecteurs 768 dimensions
- Temps calcul < 1s/question

**Estimation** : 1h30

---

### [031] TODO D√©velopper biobert_client.py ‚Äî calcul score

**Description** : cr√©er centro√Ødes par module (seed-sentences), calculer cosine similarity, ajouter champ `biomedical_score`

**D√©pendances** : [030]

**Fichiers concern√©s** :
- `scripts/ai_generation/biobert_client.py`

**Crit√®res de validation** :
- Scores sur √©chantillon : coh√©rents (pharma > respiratoire)
- Score ‚àà [0, 1]

**Estimation** : 1h30

---

### [031b] TODO Appliquer seuils BioBERT adaptatifs par module

**Description** : charger seuils depuis `metadata.json`, appliquer par module dans validation, logger rejets par motif

**D√©pendances** : [031], [025b]

**Fichiers concern√©s** :
- `scripts/ai_generation/biobert_client.py`

**Crit√®res de validation** :
- Logs montrent seuils diff√©renci√©s appliqu√©s (pharma: 0.10, respiratoire: 0.05)
- Rejet si `biomedical_score < threshold[module]`

**Estimation** : 1h

---

### [032] TODO Ex√©cuter scoring BioBERT complet

**Description** : lancer `biobert_client.py` sur `generated_raw.json`

**D√©pendances** : [031b], [023]

**Fichiers concern√©s** :
- `src/data/questions/generated_biobert.json`

**Crit√®res de validation** :
- 100% questions scor√©es (champ `biomedical_score` pr√©sent)
- Temps total < 3h (pour 2500 Q)

**Estimation** : 2h (+ 2h temps machine)

---

### [026] TODO Ajouter calcul context_score dans semantic_validator.py

**Description** : calculer cosine_similarity(question_embedding, source_chunk_embedding), embeddings via BioBERT ou sentence-transformers

**D√©pendances** : [032], [019]

**Fichiers concern√©s** :
- `scripts/ai_generation/semantic_validator.py`

**Crit√®res de validation** :
- Champ `context_score` ajout√©, test sur 10 questions
- Score ‚àà [0, 1], coh√©rent (score √©lev√© si question proche chunk)

**Estimation** : 1h30

---

### [027] TODO Ajouter calcul keywords_overlap dans semantic_validator.py

**Description** : extraire mots-cl√©s question, calculer intersection avec `keywords.json[module_id]`, overlap = len(intersection) / len(module_keywords)

**D√©pendances** : [026]

**Fichiers concern√©s** :
- `scripts/ai_generation/semantic_validator.py`

**Crit√®res de validation** :
- Champ `keywords_overlap` ajout√©, test sur 10 questions
- Overlap ‚àà [0, 1]

**Estimation** : 1h

---

### [038] TODO D√©velopper validation combin√©e (rejette si score < seuil)

**Description** : filtre questions : rejette si `biomedical_score < threshold` OU `context_score < 0.75` OU `keywords_overlap < 0.5`, logs d√©taill√©s motif rejet

**D√©pendances** : [027]

**Fichiers concern√©s** :
- `scripts/ai_generation/semantic_validator.py`

**Crit√®res de validation** :
- Taux rejet calcul√© par module
- Logs montrent motif rejet pour chaque question rejet√©e

**Estimation** : 1h

---

### [039] TODO Ex√©cuter validation s√©mantique compl√®te

**Description** : lancer `semantic_validator.py` sur `generated_biobert.json`

**D√©pendances** : [038]

**Fichiers concern√©s** :
- `src/data/questions/generated_scored.json`

**Crit√®res de validation** :
- ‚â• 2000 questions passent les seuils
- Taux rejet global < 20%
- Logs montrent r√©partition rejets par motif

**Estimation** : 1h30 (+ 1h30 temps machine)

---

## Phase 5 : Compilation & Examens (J14-J16)

### [033] TODO D√©velopper validate_all.py ‚Äî d√©duplication

**Description** : hash unique `sha256(text + "|" + options_sorted + "|" + module_id)`, suppression doublons exacts

**D√©pendances** : [039]

**Fichiers concern√©s** :
- `scripts/ai_generation/validate_all.py`

**Crit√®res de validation** :
- Aucun doublon dans sortie (v√©rification hash)
- Logs montrent nombre doublons supprim√©s

**Estimation** : 1h

---

### [034] TODO D√©velopper validate_all.py ‚Äî validation format

**Description** : v√©rifier exactement 4 options, `correctAnswer ‚àà [0, 1, 2, 3]`, options distinctes (no duplicates)

**D√©pendances** : [033]

**Fichiers concern√©s** :
- `scripts/ai_generation/validate_all.py`

**Crit√®res de validation** :
- 100% questions conformes apr√®s filtrage
- Questions non conformes rejet√©es avec log

**Estimation** : 1h

---

### [035] TODO D√©velopper validate_all.py ‚Äî distribution difficult√©s

**Description** : lissage distribution par module (cible: 40% easy / 40% medium / 20% hard), r√©√©quilibrage si √©cart > 10%

**D√©pendances** : [034]

**Fichiers concern√©s** :
- `scripts/ai_generation/validate_all.py`

**Crit√®res de validation** :
- Distribution globale conforme (tol√©rance ¬±10%)
- Logs montrent r√©√©quilibrage appliqu√© si n√©cessaire

**Estimation** : 1h30

---

### [035b] TODO Impl√©menter r√®gle automatique classification difficult√©s

**Description** : `difficulty = "hard"` si `context_score > 0.9` ET `len(explanation.split()) > 40`, `difficulty = "easy"` si `context_score < 0.65` OU `len(explanation) < 20`, sinon `"medium"`

**D√©pendances** : [035]

**Fichiers concern√©s** :
- `scripts/ai_generation/validate_all.py`

**Crit√®res de validation** :
- Distribution conforme apr√®s application r√®gle
- Logs montrent classification automatique appliqu√©e

**Estimation** : 1h

---

### [036] TODO D√©velopper classify_modes.py

**Description** : r√©partition revision / entrainement / concours selon difficult√© + granularit√© explication, pond√©ration annales pour concours

**D√©pendances** : [035b]

**Fichiers concern√©s** :
- `scripts/ai_generation/classify_modes.py`

**Crit√®res de validation** :
- 3 fichiers g√©n√©r√©s avec r√©partition coh√©rente
- R√©vision : toutes difficult√©s, Concours : pond√©ration annales appliqu√©e

**Estimation** : 1h

---

### [037] TODO Ex√©cuter consolidation finale

**Description** : lancer `validate_all.py` + `classify_modes.py`, g√©n√©rer `compiled.json`

**D√©pendances** : [036]

**Fichiers concern√©s** :
- `src/data/questions/validated.json`
- `src/data/questions/revision.json`
- `src/data/questions/entrainement.json`
- `src/data/questions/concours.json`
- `src/data/questions/compiled.json`

**Crit√®res de validation** :
- ‚â• 2000 QCM dans `compiled.json`
- Taux rejet final < 20%
- Chaque fichier mode conforme sch√©ma

**Estimation** : 1h

---

### [056] TODO D√©velopper exam_builder.py ‚Äî cr√©ation 6 examens calibr√©s

**Description** : tirer 60 QCM pond√©r√©s par module & difficult√© pour chaque examen th√©matique (cf. spec.md Section IV √âtape 9)

**D√©pendances** : [037], [025]

**Fichiers concern√©s** :
- `scripts/ai_generation/exam_builder.py`

**Crit√®res de validation** :
- 6 examens √ó 60 Q g√©n√©r√©s
- Chaque examen conforme sch√©ma (spec.md Section III)

**Estimation** : 2h

---

### [057] TODO V√©rifier √©quilibre examens blancs

**Description** : v√©rifier chaque module pr√©sent dans ‚â• 4 examens, difficult√© √©quilibr√©e (30/50/20)

**D√©pendances** : [056]

**Fichiers concern√©s** :
- `docs/exam_balance_report.md`

**Crit√®res de validation** :
- Rapport g√©n√©r√©, crit√®res respect√©s
- Ajustements appliqu√©s si n√©cessaire

**Estimation** : 1h

---

### [065] TODO D√©velopper coverage_report.py ‚Äî rapport couverture & fid√©lit√©

**Description** : synth√®se nb QCM/module, couverture pages (%), taux rejet (%), moyennes scores (BioBERT, context, keywords, stylistic), liste chunks orphelins

**D√©pendances** : [037]

**Fichiers concern√©s** :
- `scripts/reports/coverage_report.py`

**Crit√®res de validation** :
- Script ex√©cutable, sortie Markdown valide

**Estimation** : 1h30

---

### [066] TODO Ex√©cuter g√©n√©ration rapport de couverture

**Description** : lancer `coverage_report.py`

**D√©pendances** : [065]

**Fichiers concern√©s** :
- `docs/coverage_report.md`

**Crit√®res de validation** :
- Couverture ‚â• 90% du corpus
- Rapport lisible, m√©triques compl√®tes

**Estimation** : 30 min

---

### [066b] TODO G√©n√©rer rapport visuel fid√©lit√© (HTML + heatmap)

**Description** : cr√©er `fidelity_report_visual.py`, g√©n√©rer HTML avec table keywords_overlap par module + heatmap (rouge < 0.5, vert > 0.7)

**D√©pendances** : [066]

**Fichiers concern√©s** :
- `scripts/reports/fidelity_report_visual.py`
- `docs/fidelity_report.html`

**Crit√®res de validation** :
- Rapport HTML affich√© correctement (table + heatmap)
- Lisible par humain, export PDF possible

**Estimation** : 2h

---

## Phase 6 : Frontend Core (J17-J19)

### [040] TODO Cr√©er Zustand store useUserStore.ts

**Description** : interface `UserStats`, actions (incrementAttempt, addFeedback, addExamResult, getWeakModules, getStreakDays), persistance localStorage (`iade_user_stats_v1`)

**D√©pendances** : [002]

**Fichiers concern√©s** :
- `src/store/useUserStore.ts`

**Crit√®res de validation** :
- Tests unitaires du store (increment, persistance)
- localStorage sauvegard√© apr√®s action

**Estimation** : 1h30

---

### [040b] TODO Impl√©menter m√©canisme purge localStorage

**Description** : fonction `purgeOldLogs()` : supprime logs > 90 jours, ex√©cut√©e au d√©marrage app, conserve `examResults` ind√©finiment

**D√©pendances** : [040]

**Fichiers concern√©s** :
- `src/store/useUserStore.ts`

**Crit√®res de validation** :
- Logs purg√©s apr√®s 90 jours (test manuel avec date modifi√©e)
- `examResults` conserv√©s

**Estimation** : 1h

---

### [041] TODO Cr√©er composant QuestionCard.tsx

**Description** : affichage question + 4 options (boutons radio), s√©lection r√©ponse, affichage correction (vert/rouge) conditionnel, explication

**D√©pendances** : [002]

**Fichiers concern√©s** :
- `src/components/QuestionCard.tsx`

**Crit√®res de validation** :
- Render test avec question mock
- Interaction : clic option ‚Üí feedback visuel

**Estimation** : 2h

---

### [042] TODO Cr√©er composant RevisionMode.tsx

**Description** : liste filtrable par module (dropdown), int√©gration `QuestionCard`, explication imm√©diate, bouton "Voir le cours", marquage "√Ä revoir"

**D√©pendances** : [041], [040], [037]

**Fichiers concern√©s** :
- `src/components/RevisionMode.tsx`

**Crit√®res de validation** :
- Navigation fluide, filtrage fonctionne
- Bouton "Voir le cours" affiche panneau source_context

**Estimation** : 3h

---

### [043] TODO Cr√©er composant TrainingMode.tsx

**Description** : s√©lection module, logique 10 questions (s√©quence fixe v0, adaptatif v1 Phase 7), affichage score temps r√©el

**D√©pendances** : [041], [040], [037]

**Fichiers concern√©s** :
- `src/components/TrainingMode.tsx`

**Crit√®res de validation** :
- Parcours complet 10Q, score affich√©
- Donn√©es sauvegard√©es dans `useUserStore`

**Estimation** : 3h

---

### [044] TODO Setup routing et navigation

**Description** : React Router, routes (/, /revision, /entrainement, /concours, /dashboard), menu navigation fixe, breadcrumb

**D√©pendances** : [042], [043]

**Fichiers concern√©s** :
- `src/App.tsx`
- `src/main.tsx`
- `src/components/Navigation.tsx`

**Crit√®res de validation** :
- Navigation entre modes fonctionnelle
- URLs correctes, breadcrumb affich√©

**Estimation** : 1h

---

## Phase 7 : Modes Avanc√©s (J20-J22)

### [050] TODO Cr√©er composant ExamMode.tsx

**Description** : chronom√®tre 120 min, navigation libre entre 60 questions (boutons prev/next), blocage explications pendant √©preuve, correction √† la fin uniquement

**D√©pendances** : [041], [040], [056]

**Fichiers concern√©s** :
- `src/components/ExamMode.tsx`

**Crit√®res de validation** :
- Parcours complet 60Q avec chronom√®tre
- Explications bloqu√©es pendant examen, affich√©es apr√®s soumission

**Estimation** : 4h

---

### [051] TODO Impl√©menter logique adaptative TrainingMode

**Description** : algorithme progression (d√©marre easy, si p(bonne) > 0.7 ‚Üí +niveau, si < 0.4 ‚Üí -niveau), s√©lection dynamique questions

**D√©pendances** : [043]

**Fichiers concern√©s** :
- `src/utils/adaptiveLogic.ts`
- `src/components/TrainingMode.tsx`

**Crit√®res de validation** :
- Test sur plusieurs sessions : niveau ajuste correctement
- Logs montrent progression niveau

**Estimation** : 2h30

---

### [052] TODO Impl√©menter syst√®me feedback utilisateur

**Description** : UI boutons Bad (1) / Good (2) / Very Good (3), sauvegarde dans `useUserStore.feedbackLog`

**D√©pendances** : [040], [041]

**Fichiers concern√©s** :
- `src/components/QuestionCard.tsx`
- `src/store/useUserStore.ts`

**Crit√®res de validation** :
- Feedback enregistr√© et r√©cup√©rable
- Affichage historique feedback dans Dashboard (Phase 8)

**Estimation** : 1h30

---

### [053] TODO Impl√©menter persistance localStorage compl√®te

**Description** : sauvegarde automatique apr√®s chaque action (r√©ponse, feedback, fin examen), r√©cup√©ration au d√©marrage, migration schema si n√©cessaire

**D√©pendances** : [040]

**Fichiers concern√©s** :
- `src/store/useUserStore.ts`

**Crit√®res de validation** :
- Donn√©es persist√©es apr√®s refresh
- Migration schema v0 ‚Üí v1 fonctionnelle si structure change

**Estimation** : 1h

---

## Phase 8 : Dashboard & Analytics (J23-J24)

### [060] TODO Cr√©er composant Dashboard.tsx

**Description** : affichage score global (correct/attempts √ó 100), jours actifs (calendrier heatmap optionnel)

**D√©pendances** : [040]

**Fichiers concern√©s** :
- `src/components/Dashboard.tsx`

**Crit√®res de validation** :
- M√©triques calcul√©es correctement (score, jours actifs)
- Affichage visuel clair (jauge circulaire pour score)

**Estimation** : 2h

---

### [061] TODO Ajouter identification modules faibles

**Description** : tri `byModule` par (correct/attempts), affichage top 5 modules √† travailler, barre progression par module

**D√©pendances** : [060]

**Fichiers concern√©s** :
- `src/components/Dashboard.tsx`

**Crit√®res de validation** :
- Identification correcte sur donn√©es test
- Top 5 affich√© avec scores

**Estimation** : 1h30

---

### [062] TODO Ajouter graphique progression

**Description** : EMA 7 jours des scores, library chart (recharts), graphique ligne

**D√©pendances** : [060]

**Fichiers concern√©s** :
- `src/components/Dashboard.tsx`

**Crit√®res de validation** :
- Graphique affich√© correctement
- Courbe EMA calcul√©e (fen√™tre glissante 7 jours)

**Estimation** : 2h

---

### [063] TODO Ajouter historique examens blancs

**Description** : tableau avec scores, dates, dur√©es des examens pass√©s, tri par date d√©croissant

**D√©pendances** : [050], [060]

**Fichiers concern√©s** :
- `src/components/Dashboard.tsx`

**Crit√®res de validation** :
- Historique affich√© et persistant
- Tableau tri√© correctement

**Estimation** : 1h

---

## Phase 9 : QA & Polish (J25-J26)

### [069] TODO Cr√©er test pipeline global

**Description** : `tests/test_pipeline.py` : ex√©cute pipeline complet sur 1 module (5 pages), v√©rifie coh√©rence compteurs (`n_valid√©s == n_g√©n√©r√©s - n_rejet√©s`), conservation `chunk_id`

**D√©pendances** : [037]

**Fichiers concern√©s** :
- `tests/test_pipeline.py`

**Crit√®res de validation** :
- Test passe (coh√©rence compteurs valid√©e)
- Coverage : pipeline complet end-to-end

**Estimation** : 3h

---

### [070] TODO Tests unitaires Python ‚Äî extraction

**Description** : tests sur `extract_pdfs.py`, mocks de PDF (fixtures), validation d√©tection titres, d√©coupage chunks, token count < 1200

**D√©pendances** : [011]

**Fichiers concern√©s** :
- `tests/test_extraction.py`

**Crit√®res de validation** :
- Coverage ‚â• 80%
- Tous tests passent

**Estimation** : 2h

---

### [071] TODO Tests unitaires Python ‚Äî validation

**Description** : tests sur `validate_all.py`, tests d√©duplication, format (4 options, correctAnswer valide), distribution difficult√©s

**D√©pendances** : [035]

**Fichiers concern√©s** :
- `tests/test_validation.py`

**Crit√®res de validation** :
- Coverage ‚â• 80%
- Tous tests passent

**Estimation** : 2h

---

### [072] TODO Tests unitaires React ‚Äî composants

**Description** : tests `QuestionCard`, `RevisionMode`, `TrainingMode`, `ExamMode`, `Dashboard` (Testing Library + Vitest)

**D√©pendances** : [041], [042], [043], [050], [060]

**Fichiers concern√©s** :
- `src/components/__tests__/*.test.tsx`

**Crit√®res de validation** :
- Coverage ‚â• 70%
- Tous tests passent

**Estimation** : 3h

---

### [073] TODO Tests d'int√©gration end-to-end

**Description** : parcours complet utilisateur (r√©vision ‚Üí entra√Ænement ‚Üí concours ‚Üí dashboard) avec Playwright ou Cypress

**D√©pendances** : [044], [050], [060]

**Fichiers concern√©s** :
- `e2e/*.spec.ts`

**Crit√®res de validation** :
- Sc√©narios principaux passent (r√©vision, entra√Ænement, concours, dashboard)
- Aucune erreur console critique

**Estimation** : 3h

---

### [074] TODO Spot-check expert sur 50 questions

**Description** : s√©lection al√©atoire 50 questions (apr√®s validation compl√®te), revue manuelle qualit√© (coh√©rence biom√©dicale, pertinence p√©dagogique, exactitude factuelle), calcul taux accord

**D√©pendances** : [037]

**Fichiers concern√©s** :
- `docs/spot_check_report.md`

**Crit√®res de validation** :
- Taux ‚â• 90%
- Rapport d√©taill√© avec exemples

**Estimation** : 2h

---

### [075] TODO Ajustements prompts si n√©cessaire

**Description** : si taux < 90%, analyser causes (prompt trop vague, BioBERT insuffisant, chunks bruit√©s), it√©rer sur prompts, re-g√©n√©ration partielle, re-validation

**D√©pendances** : [074]

**Fichiers concern√©s** :
- `scripts/ai_generation/generate_batch.py`

**Crit√®res de validation** :
- Taux ‚â• 90% atteint
- Logs montrent it√©rations prompts

**Estimation** : variable (2-6h selon besoin)

---

### [074b] TODO V√©rification fid√©lit√© lexicale automatique

**Description** : script `fidelity_check.py` : % mots-cl√©s partag√©s QCM ‚Üî chunk, rejet si < 50%, rapport par module

**D√©pendances** : [037], [019]

**Fichiers concern√©s** :
- `scripts/reports/fidelity_check.py`
- `docs/fidelity_report.md`

**Crit√®res de validation** :
- 90% QCM valides lexicalement (‚â• 50% overlap)
- Rapport g√©n√©r√© avec d√©tails par module

**Estimation** : 1h30

---

### [080] TODO UX/UI refinement

**Description** : coh√©rence visuelle (couleurs Tailwind, espacements), responsive design (mobile-friendly), animations et transitions (Framer Motion optionnel)

**D√©pendances** : [044], [050], [060]

**Fichiers concern√©s** :
- Tous les composants UI

**Crit√®res de validation** :
- Revue visuelle compl√®te (desktop + mobile)
- Aucune incoh√©rence visuelle

**Estimation** : 3h

---

### [081] TODO R√©diger README.md utilisateur

**Description** : installation et pr√©requis, d√©marrage rapide, utilisation des 3 modes, FAQ

**D√©pendances** : [080]

**Fichiers concern√©s** :
- `README.md`

**Crit√®res de validation** :
- Lecture par utilisateur test (feedback positif)
- Instructions claires, screenshots

**Estimation** : 1h30

---

### [082] TODO R√©diger guide d√©veloppeur

**Description** : architecture technique, scripts disponibles, contribution, roadmap

**D√©pendances** : [080]

**Fichiers concern√©s** :
- `docs/DEVELOPER.md`

**Crit√®res de validation** :
- Documentation compl√®te (architecture, scripts, tests)
- Exemples de contribution

**Estimation** : 1h30

---

### [083] TODO Nettoyage du code et linting

**Description** : ESLint + Prettier frontend, Black + Flake8 backend, suppression code mort, commentaires manquants

**D√©pendances** : [080]

**Fichiers concern√©s** :
- Tous les fichiers source

**Crit√®res de validation** :
- Aucune erreur linter
- Code format√© uniform√©ment

**Estimation** : 2h

---

### [084] TODO Audit final qualit√© donn√©es

**Description** : v√©rification distribution modules, absence doublons (re-v√©rification), coh√©rence metadata, m√©triques finales

**D√©pendances** : [037], [057], [066]

**Fichiers concern√©s** :
- `compiled.json`
- `metadata.json`

**Crit√®res de validation** :
- M√©triques v1 toutes atteintes (cf. plan.md)
- Aucun doublon d√©tect√©

**Estimation** : 1h

---

### [085] TODO G√©n√©rer rapport final qualit√© IADE NEW

**Description** : `final_report.md` : QCM total, couverture corpus, coh√©rence biom√©dicale moyenne, similarit√© moyenne, taux accord expert, toutes m√©triques v1

**D√©pendances** : [084], [074], [074b]

**Fichiers concern√©s** :
- `docs/final_report.md`

**Crit√®res de validation** :
- Tous les seuils atteints (tableau m√©triques)
- Rapport lisible, exportable PDF

**Estimation** : 1h

---

### [086] TODO Cr√©er script run_all.sh (pipeline complet)

**Description** : script bash ex√©cutant s√©quentiellement extraction ‚Üí indexation ‚Üí g√©n√©ration ‚Üí validation ‚Üí compilation ‚Üí examens ‚Üí rapports

**D√©pendances** : [085]

**Fichiers concern√©s** :
- `scripts/run_all.sh`

**Crit√®res de validation** :
- Pipeline complet ex√©cutable en 1 commande
- Logs d√©taill√©s, arr√™t si erreur critique

**Estimation** : 1h

---

### [086b] TODO Ajouter option --subset N dans run_all.sh

**Description** : `--subset 10` ex√©cute pipeline sur 10 modules seulement (dry run rapide avant full run)

**D√©pendances** : [086]

**Fichiers concern√©s** :
- `scripts/run_all.sh`

**Crit√®res de validation** :
- Dry run sur 10 modules < 2h
- Option `--subset N` fonctionnelle

**Estimation** : 1h

---

## R√©capitulatif des T√¢ches

### Par Phase

| Phase | Nombre de t√¢ches | Dur√©e estim√©e |
|-------|------------------|---------------|
| 0 | 5 | 2h30 |
| 1 | 5 | 8-10h |
| 2 | 6 | 5-6h |
| 3 | 5 | 6-8h (+ 5h machine) |
| 4 | 8 | 8-10h (+ 3h machine) |
| 5 | 10 | 8-10h |
| 6 | 5 | 8-10h |
| 7 | 4 | 8-10h |
| 8 | 4 | 5-6h |
| 9 | 16 | 10-12h |
| 10 | 5 | 2-3h |

**Total** : 106 t√¢ches, ~72-87h travail effectif (hors temps machine ~10h)

### Par Statut (actuel)

- `TODO` : 102 t√¢ches (101 initiales + 3 Phase 10 - 2 done)
- `IN PROGRESS` : 0
- `DONE` : 2 t√¢ches (102, 103 - Phase 10)
- `BLOCKED` : 0

### T√¢ches Critiques (chemin critique)

Les t√¢ches suivantes sont sur le chemin critique et bloquent les phases suivantes si non termin√©es :

- [011] D√©coupage chunks (bloque Phase 2)
- [019] Indexation compl√®te (bloque Phase 3)
- [023] G√©n√©ration batch (bloque Phase 4)
- [039] Validation s√©mantique (bloque Phase 5)
- [037] Consolidation finale (bloque Phase 6)
- [056] Examens blancs (bloque Phase 7 ExamMode)

### Nouvelles T√¢ches (vs plan initial)

T√¢ches ajout√©es dans le plan optimis√© :

- [024b] stylistic_validator.py (Phase 2)
- [025b] Config seuils BioBERT adaptatifs (Phase 2)
- [023b] Feedback it√©ratif stylistique (Phase 3)
- [031b] Application seuils adaptatifs (Phase 4)
- [035b] R√®gle auto difficult√©s (Phase 5)
- [066b] Rapport visuel HTML + heatmap (Phase 5)
- [040b] Purge localStorage (Phase 6)
- [069] Test pipeline global (Phase 9)
- [074b] V√©rification fid√©lit√© lexicale auto (Phase 9)
- [086b] Option --subset (Phase 9)

**Total nouvelles t√¢ches** : 10 (10% du total)

---

## M√©triques de Validation Finales (rappel)

Toutes les t√¢ches doivent contribuer √† atteindre ces m√©triques :

| Crit√®re | Objectif | Valid√© par t√¢che |
|---------|----------|------------------|
| Couverture corpus | ‚â• 90% | [066] |
| Nombre total QCM | ‚â• 2000 | [037] |
| Examens blancs | 6 √ó 60 Q | [056] |
| Fid√©lit√© s√©mantique | ‚â• 0.75 | [039] |
| Overlap lexical | ‚â• 0.5 | [074b] |
| Score BioBERT adaptatif | 0.05-0.10 | [031b] |
| Taux rejet global | < 20% | [039] |
| Accord expert | ‚â• 90% | [074] |
| Distance stylistique | < 0.3 | [023b] |
| Coh√©rence pipeline | 100% | [069] |

---

## R√®gles d'Ex√©cution

1. **Ordre strict** : respecter les d√©pendances (une t√¢che ne peut d√©marrer que si ses d√©pendances sont `DONE`)

2. **1 commit = 1 t√¢che** : apr√®s chaque t√¢che `DONE`, commit avec message `[NUMERO] Titre de la t√¢che`

3. **Documentation des ajustements** : si modification n√©cessaire (seuils, prompts), documenter dans commit message

4. **Tests avant passage phase suivante** : valider crit√®res de validation de chaque t√¢che avant de passer √† la suivante

5. **Logs d√©taill√©s** : chaque script Python doit logger (niveau INFO) : d√©but, progression, fin, erreurs

6. **Gestion erreurs** : si une t√¢che √©choue 3√ó ‚Üí marquer `BLOCKED`, documenter cause, proposer solution

---

## Phase 10 : Linguistic Optimization & Quality Refinement (Post-MVP)

### [102] DONE Identifier les QCM de faible qualit√©

**Description** : scanner tous les fichiers QCM et filtrer ceux avec score BioBERT < 0.70, explications vides ou distracteurs non plausibles

**D√©pendances** : [037] Consolidation finale corpus

**Fichiers concern√©s** :
- `scripts/refinement/filter_low_quality.py`
- `src/data/questions/to_refine.json`

**Crit√®res de validation** :
- ‚úÖ 213 QCM identifi√©s comme faibles
- ‚úÖ Fichier `to_refine.json` cr√©√©

**Estimation** : 20 min

**Statut** : ‚úÖ DONE

---

### [103] DONE R√©√©criture IA biom√©dicale (fond)

**Description** : utiliser Ollama (Mistral) pour reformuler les QCM faibles en am√©liorant la coh√©rence biom√©dicale, les explications et les distracteurs tout en conservant la bonne r√©ponse

**D√©pendances** : [102] Identifier QCM faibles

**Fichiers concern√©s** :
- `scripts/refinement/refine_batch.py`
- `src/data/questions/to_refine_refined.json`

**Crit√®res de validation** :
- ‚úÖ 213 QCM trait√©s
- ‚úÖ 212 QCM raffin√©s avec succ√®s (marked `refined=True`)
- ‚úÖ Fichier `to_refine_refined.json` cr√©√©

**Estimation** : ~40 min (temps machine Ollama)

**Statut** : ‚úÖ DONE

---

### [104] ‚úÖ DONE Recalcul BioBERT + fusion dans corpus principal

**Description** : recalculer les scores BioBERT des QCM raffin√©s, valider qu'ils d√©passent le seuil 0.88, d√©duplication, et fusionner dans `compiled.json`

**D√©pendances** : [103] R√©√©criture IA

**Fichiers concern√©s** :
- `scripts/refinement/revalidate_refined.py`
- `scripts/refinement/deduplicate_chunk_ids.py`
- `scripts/refinement/merge_corpus.py`
- `src/data/questions/compiled_dedup.json`
- `src/data/questions/compiled_refined.json`

**Crit√®res de validation** :
- ‚úÖ Score BioBERT moyen des raffin√©s : 0.932 (> 0.88)
- ‚úÖ 102/213 QCM accept√©s apr√®s revalidation (47.9%)
- ‚úÖ D√©duplication : 462 ‚Üí 165 QCM uniques
- ‚úÖ Fusion r√©ussie : 165 QCM finaux, 0 perte

**Estimation** : 30 min

**R√©sultats** :
- 165 QCM uniques (d√©dupliqu√©s par chunk_id)
- 102 QCM remplac√©s par versions raffin√©es (61.8%)
- Score biom√©dical moyen : 0.932 (+9.5% vs v1.0)

**Statut** : ‚úÖ DONE

---

### [105] TODO Optimisation linguistique (forme)

**Description** : scanner tous les QCM v1.1 et reformuler ceux avec score de fluidit√© < 7/10, en conservant le sens m√©dical et les r√©ponses

**D√©pendances** : [104] Revalidation BioBERT

**Fichiers concern√©s** :
- `scripts/refinement/optimize_phrasing.py`
- `src/data/questions/compiled_refined_optimized.json`

**Crit√®res de validation** :
- ‚úÖ √âvaluation de 165 QCM (score fluidit√© 0-10)
- ‚úÖ Reformulation des questions avec score < 7
- ‚úÖ Sens m√©dical pr√©serv√©
- ‚úÖ Options et r√©ponses correctes inchang√©es

**Estimation** : ~20-30 min (temps machine Ollama)

**Statut** : TODO (pr√™t √† ex√©cuter)

---

### [106] TODO Validation coh√©rence finale

**Description** : v√©rifier la coh√©rence du corpus v1.1 final (post-optimisation linguistique) et g√©n√©rer rapport final de qualit√©

**D√©pendances** : [105] Optimisation linguistique

**Fichiers concern√©s** :
- `scripts/refinement/revalidate_refined.py`
- `logs/final_quality_report.json`

**Crit√®res de validation** :
- Score BioBERT global ‚â• 0.88
- Aucune r√©gression d√©tect√©e
- Rapport de qualit√© g√©n√©r√©

**Estimation** : 20 min

**Statut** : TODO

---

## R√©sum√© Phase 10

**Objectif** : am√©liorer la qualit√© linguistique et biom√©dicale des QCM apr√®s MVP

**T√¢ches** : 5 (102-106)

**Dur√©e estim√©e** : ~2h30 (dont ~1h40 temps machine Ollama)

**Statut** :
- ‚úÖ DONE : 4 t√¢ches (102, 103, 104 + enrichissement m√©tadonn√©es)
- üïí TODO : 2 t√¢ches (105, 106)

---

# PHASE 10+ ‚Äî D√©ploiement v1.1 en Production

## [107] ‚úÖ DONE Enrichissement m√©tadonn√©es

**Description** : ajouter source_pdf, page_number et difficulty √† chaque QCM du corpus v1.1

**D√©pendances** : [104] Fusion corpus

**Fichiers concern√©s** :
- `scripts/refinement/enrich_metadata.py`
- `src/data/questions/compiled_refined_enriched.json`

**Crit√®res de validation** :
- ‚úÖ 165 QCM enrichis avec source_pdf
- ‚úÖ 165 QCM enrichis avec page_number
- ‚úÖ 165 QCM enrichis avec difficulty
- ‚úÖ Mapping chunk ‚Üí PDF/page fonctionnel

**Estimation** : 10 min

**R√©sultats** :
- 198 chunks mapp√©s (modules ‚Üí PDF)
- 165/165 QCM avec m√©tadonn√©es compl√®tes
- Distribution difficult√©s calcul√©e

**Statut** : ‚úÖ DONE

---

## [108] ‚úÖ DONE D√©ploiement production

**Description** : remplacer les fichiers de production (compiled.json, revision.json, etc.) par le corpus v1.1 enrichi

**D√©pendances** : [107] Enrichissement m√©tadonn√©es

**Fichiers concern√©s** :
- `scripts/production/deploy_v1.1.py`
- `src/data/questions/compiled.json`
- `src/data/questions/revision.json`
- `src/data/questions/entrainement.json`
- `src/data/questions/concours.json`
- `public/data/questions/*.json`

**Crit√®res de validation** :
- ‚úÖ Backup des fichiers existants cr√©√©s (timestamp)
- ‚úÖ Fichiers production mis √† jour avec corpus v1.1
- ‚úÖ 165 QCM disponibles en production
- ‚úÖ Application frontend fonctionnelle

**Estimation** : 5 min

**Statut** : ‚úÖ DONE

---

## [109] ‚úÖ DONE R√©g√©n√©ration examens blancs

**Description** : validation des 6 examens blancs avec le corpus v1.1 (165 QCM raffin√©s)

**D√©pendances** : [108] D√©ploiement production

**Fichiers concern√©s** :
- `scripts/ai_generation/exam_builder.py`
- `public/data/exams/exam_01_physio_pharma.json` ‚Üí `exam_06_mixte.json`

**Crit√®res de validation** :
- ‚úÖ 6 examens de 60 questions valid√©s
- ‚úÖ Distribution √©quilibr√©e par module
- ‚úÖ Toutes les r√©f√©rences coh√©rentes avec corpus v1.1
- ‚úÖ Examens accessibles en production

**Estimation** : 5 min

**R√©sultats** :
- 6 examens blancs valid√©s et fonctionnels
- Aucune r√©f√©rence manquante
- Pr√™ts pour utilisation

**Statut** : ‚úÖ DONE

---

## [110] ‚úÖ DONE G√©n√©ration notes de release

**Description** : g√©n√©rer automatiquement les notes de release v1.1 pour GitHub

**D√©pendances** : [107] Enrichissement m√©tadonn√©es

**Fichiers concern√©s** :
- `scripts/production/create_release_notes.py`
- `RELEASE_NOTES_v1.1.md`

**Crit√®res de validation** :
- ‚úÖ Notes de release markdown g√©n√©r√©es
- ‚úÖ Statistiques corpus v1.1 incluses
- ‚úÖ Changelog v1.0 ‚Üí v1.1 d√©taill√©
- ‚úÖ Guide d'installation √† jour

**Estimation** : 5 min

**Statut** : ‚úÖ DONE

---

## [111] ‚úÖ DONE Publication GitHub v1.1

**Description** : cr√©er la release officielle v1.1 sur GitHub avec archive corpus et documentation

**D√©pendances** : [110] Notes de release

**Fichiers concern√©s** :
- `export_for_ai/iade_qcm_v1.1_export.tar.gz`
- GitHub release page

**Commande ex√©cut√©e** :
```bash
gh release create v1.1 \
  ./export_for_ai/iade_qcm_v1.1_export.tar.gz \
  --title "IADE NEW v1.1 ‚Äì Corpus raffin√© et valid√©" \
  --notes-file RELEASE_NOTES_v1.1.md
```

**Crit√®res de validation** :
- ‚úÖ Release v1.1 cr√©√©e sur GitHub
- ‚úÖ Archive corpus attach√©e (173 KB)
- ‚úÖ Notes de release publi√©es
- ‚úÖ Tag v1.1 cr√©√©

**URL** : https://github.com/Soynido/IADE-NEW/releases/tag/v1.1

**Estimation** : 5 min

**Statut** : ‚úÖ DONE

---

## R√©sum√© Phase 10+

**Objectif** : d√©ployer le corpus v1.1 raffin√© en production et publier la release officielle

**T√¢ches** : 5 (107-111)

**Dur√©e estim√©e** : ~30 min

**Statut** :
- ‚úÖ DONE : 5 t√¢ches (107-111)
- üïí TODO : 0 t√¢ches

---

# PHASE 11 ‚Äî Post-v1.1 (Audit & Expansion)

## [112] TODO Audit externe qualit√©

**Description** : faire √©valuer 20 QCM al√©atoires par un expert IADE ou enseignant pour valider la corr√©lation entre score BioBERT et jugement humain

**D√©pendances** : [111] Publication v1.1

**Fichiers concern√©s** :
- `scripts/evaluation/external_audit.py`
- `docs/external_audit_report.md`

**Crit√®res de validation** :
- 20 QCM √©valu√©s par expert
- Corr√©lation score BioBERT ‚Üî jugement humain mesur√©e
- Taux d'accord ‚â• 85%
- Recommandations d'am√©lioration document√©es

**Estimation** : 2-3h (selon disponibilit√© expert)

**Statut** : TODO

---

## [113] TODO Pr√©paration g√©n√©ration v2

**Description** : cr√©er script de diversification contr√¥l√©e pour g√©n√©rer variantes des 165 chunks existants (objectif : 165 ‚Üí 462 QCM uniques)

**D√©pendances** : [112] Audit externe

**Fichiers concern√©s** :
- `scripts/generation_v2/diversify_chunks.py`
- `scripts/generation_v2/variant_generator.py`

**Crit√®res de validation** :
- Script de g√©n√©ration variantes cr√©√©
- M√©canisme de labeling _v2, _v3 impl√©ment√©
- Strat√©gie de diversification d√©finie (angles d'approche diff√©rents)
- Tests sur 10 chunks valid√©s

**Estimation** : 1h

**Statut** : TODO

---

## [114] TODO G√©n√©ration corpus v2 (expansion)

**Description** : g√©n√©rer 300+ QCM suppl√©mentaires par diversification des chunks existants

**D√©pendances** : [113] Pr√©paration v2

**Fichiers concern√©s** :
- `scripts/generation_v2/generate_variants.py`
- `src/data/questions/compiled_v2.json`

**Crit√®res de validation** :
- ‚â• 300 nouveaux QCM g√©n√©r√©s
- Validation BioBERT ‚â• 0.88
- Pas de doublons avec v1.1
- Distribution √©quilibr√©e par module

**Estimation** : 2-3h (temps machine)

**Statut** : TODO

---

## [115] ‚úÖ DONE Validation liens CTA vers cours

**Description** : v√©rifier que chaque QCM pointe vers une page PDF valide et que la page contient bien des mots-cl√©s li√©s √† la question

**D√©pendances** : [107] Enrichissement m√©tadonn√©es

**Fichiers concern√©s** :
- `scripts/validation/check_cta_links.py`
- `reports/cta_validation_report.json`

**Crit√®res de validation** :
- ‚úÖ Tous les PDF sources pr√©sents
- ‚úÖ Pages dans les bornes (0 erreur)
- ‚úÖ Similarit√© question ‚Üî page ‚â• 0.4
- ‚úÖ Taux de succ√®s ‚â• 85%

**Estimation** : 10 min

**R√©sultats** :
- 165/165 QCM valides (100.0%)
- 0 PDF manquant
- 0 erreur de lecture
- 0 page avec similarit√© faible
- Score moyen de similarit√© : excellent

**Statut** : ‚úÖ DONE

---

## [116] ‚úÖ DONE Alignement s√©mantique automatique

**Description** : recalculer automatiquement le meilleur PDF et la page la plus pertinente pour chaque question via similarit√© s√©mantique (SentenceTransformers)

**D√©pendances** : [115] Validation CTA

**Fichiers concern√©s** :
- `scripts/refinement/align_cta_semantic.py`
- `src/data/questions/compiled_refined_aligned.json`
- `reports/cta_alignment_report.json`

**Crit√®res de validation** :
- ‚úÖ 3 PDF extraits et encod√©s (141 pages total)
- ‚úÖ 165 QCM align√©s s√©mantiquement
- ‚úÖ Score moyen d'alignement ‚â• 0.5
- ‚úÖ 100% confiance ‚â• 0.3

**Estimation** : 5-10 min (temps encodage)

**R√©sultats** :
- Score moyen : 0.546
- Changements : 146/165 (88.5%)
- Haute confiance (‚â•0.5) : 105 QCM (63.6%)
- Moyenne confiance (0.3-0.5) : 60 QCM (36.4%)
- Faible confiance (<0.3) : 0 QCM (0.0%)
- Distribution : 63% Cours / 19% Annales V2 / 18% Annales V1

**Dur√©e r√©elle** : 77 secondes

**Statut** : ‚úÖ DONE

---

## R√©sum√© Phase 11

**Objectif** : audit qualit√© externe, validation CTA, alignement s√©mantique et expansion du corpus vers v2

**T√¢ches** : 5 (112-116)

**Dur√©e estim√©e** : ~6-8h

**Statut** :
- ‚úÖ DONE : 2 t√¢ches (115, 116)
- üïí TODO : 3 t√¢ches (112-114)

---

## Conclusion

Ce document **tasks.md** liste les **116 t√¢ches actionnables** pour livrer IADE NEW de v1.0 √† v2.0.

**Chaque t√¢che est atomique, testable et mesurable.**

**Le plan est pr√™t pour ex√©cution s√©quentielle.**

### Statut Global du Projet

| Phase | T√¢ches | Compl√©t√©es | En cours | TODO | Statut |
|-------|--------|------------|----------|------|--------|
| **Phase 0** | 4 | 4 | 0 | 0 | ‚úÖ **100%** |
| **Phase 1** | 9 | 9 | 0 | 0 | ‚úÖ **100%** |
| **Phase 2** | 6 | 6 | 0 | 0 | ‚úÖ **100%** |
| **Phase 3** | 8 | 8 | 0 | 0 | ‚úÖ **100%** |
| **Phase 4** | 7 | 7 | 0 | 0 | ‚úÖ **100%** |
| **Phase 5** | 9 | 9 | 0 | 0 | ‚úÖ **100%** |
| **Phase 6** | 22 | 22 | 0 | 0 | ‚úÖ **100%** |
| **Phase 7** | 16 | 16 | 0 | 0 | ‚úÖ **100%** |
| **Phase 8** | 11 | 11 | 0 | 0 | ‚úÖ **100%** |
| **Phase 9** | 13 | 13 | 0 | 0 | ‚úÖ **100%** |
| **Phase 10** | 5 | 4 | 0 | 2 | üü° **80%** |
| **Phase 10+** | 5 | 5 | 0 | 0 | ‚úÖ **100%** |
| **Phase 11** | 5 | 2 | 0 | 3 | üü° **40%** |
| **TOTAL** | **116** | **113** | **0** | **3** | **97%** |

### √âtapes R√©cemment Compl√©t√©es

1. ‚úÖ **[107]** Enrichissement m√©tadonn√©es
2. ‚úÖ **[108]** D√©ploiement production v1.1
3. ‚úÖ **[109]** Validation examens blancs
4. ‚úÖ **[110]** G√©n√©ration notes de release
5. ‚úÖ **[111]** Publication GitHub v1.1
6. ‚úÖ **[115]** Validation liens CTA (100%)
7. ‚úÖ **[116]** Alignement s√©mantique (146 QCM relocalis√©s)

### D√©ploiement & Services

8. ‚úÖ **Vercel** : Application d√©ploy√©e sur production
9. ‚úÖ **Redis** : Syst√®me de feedback Upstash configur√©
10. ‚úÖ **Alignement** : Corpus optimis√© s√©mantiquement

### Roadmap Post-v1.1

- **Court terme** : Audit externe (validation scientifique)
- **Moyen terme** : G√©n√©ration v2 (expansion 165 ‚Üí 462 QCM)
- **Long terme** : Mode "Cas cliniques" interactifs

---

**Version** : 1.1  
**Date** : 8 novembre 2025  
**Statut** : v1.1 D√âPLOY√âE et OP√âRATIONNELLE (97% compl√©t√©)

### Services en production

- **Application** : https://iade-kzl7d9sxw-valentin-galudec-s-projects.vercel.app
- **GitHub** : https://github.com/Soynido/IADE-NEW
- **Release** : https://github.com/Soynido/IADE-NEW/releases/tag/v1.1
- **Upstash Redis** : https://console.upstash.com/redis/full-crab-26762

