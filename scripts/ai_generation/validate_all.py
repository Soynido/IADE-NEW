#!/usr/bin/env python3
"""
Script de validation finale et consolidation
T√¢ches [033-035b] - Phase 5 : Compilation & Examens

Objectif:
- D√©duplication (hash unique)
- Validation format strict (4 options, correctAnswer valide)
- Lissage distribution difficult√©s (40/40/20)
- Classification automatique difficult√©s bas√©e sur rules
- V√©rification exhaustivit√© (chaque chunk ‚Üí ‚â•1 QCM)

Usage:
    python scripts/ai_generation/validate_all.py \
           --in generated_scored.json \
           --out validated.json
"""

import argparse
import json
import hashlib
from pathlib import Path
from typing import List, Dict, Tuple
from collections import Counter
from datetime import datetime

# =============================================================================
# CONFIGURATION
# =============================================================================

# Distribution cible par module
TARGET_DISTRIBUTION = {
    'easy': 0.40,
    'medium': 0.40,
    'hard': 0.20
}

# R√®gle automatique de classification difficult√©s
def auto_classify_difficulty(question: Dict) -> str:
    """
    Classifie automatiquement la difficult√© selon r√®gles spec.md.
    
    R√®gle:
    - hard: context_score > 0.9 ET explication > 40 mots
    - easy: context_score < 0.65 OU explication < 20 mots
    - medium: sinon
    """
    context_score = question.get('context_score', 0)
    explanation = question.get('explanation', '')
    explanation_words = len(explanation.split())
    
    if context_score > 0.9 and explanation_words > 40:
        return 'hard'
    elif context_score < 0.65 or explanation_words < 20:
        return 'easy'
    else:
        return 'medium'

# =============================================================================
# D√âDUPLICATION
# =============================================================================

def deduplicate_questions(questions: List[Dict]) -> Tuple[List[Dict], int]:
    """
    Supprime les doublons bas√©s sur hash unique.
    
    Hash: sha256(text + "|" + options_sorted + "|" + module_id)
    
    Returns:
        (questions_unique, nb_duplicates_removed)
    """
    print(f"\nüîç D√©duplication de {len(questions)} questions...")
    
    seen_hashes = set()
    unique_questions = []
    duplicates_count = 0
    
    for question in questions:
        # Construction hash
        text = question.get('text', '')
        options = sorted(question.get('options', []))
        module_id = question.get('module_id', '')
        
        hash_input = f"{text}|{options}|{module_id}"
        hash_value = hashlib.sha256(hash_input.encode()).hexdigest()
        
        if hash_value in seen_hashes:
            duplicates_count += 1
        else:
            seen_hashes.add(hash_value)
            unique_questions.append(question)
    
    print(f"   ‚úì {duplicates_count} doublons supprim√©s")
    print(f"   ‚úì {len(unique_questions)} questions uniques")
    
    return unique_questions, duplicates_count

# =============================================================================
# VALIDATION FORMAT
# =============================================================================

def validate_format(questions: List[Dict]) -> Tuple[List[Dict], int]:
    """
    Valide le format strict des questions.
    
    Contraintes:
    - Exactement 4 options
    - correctAnswer ‚àà [0, 1, 2, 3]
    - Options distinctes (pas de duplicates)
    - Texte et explication non vides
    
    Returns:
        (questions_valid, nb_invalid)
    """
    print(f"\nüîç Validation format de {len(questions)} questions...")
    
    valid_questions = []
    invalid_count = 0
    
    for question in questions:
        # Check 4 options
        options = question.get('options', [])
        if not isinstance(options, list) or len(options) != 4:
            invalid_count += 1
            continue
        
        # Check options distinctes
        if len(set(options)) != 4:
            invalid_count += 1
            continue
        
        # Check correctAnswer
        correct_answer = question.get('correctAnswer')
        if not isinstance(correct_answer, int) or correct_answer not in [0, 1, 2, 3]:
            invalid_count += 1
            continue
        
        # Check texte et explication non vides
        if not question.get('text') or not question.get('explanation'):
            invalid_count += 1
            continue
        
        valid_questions.append(question)
    
    print(f"   ‚úì {invalid_count} questions format invalide rejet√©es")
    print(f"   ‚úì {len(valid_questions)} questions format valide")
    
    return valid_questions, invalid_count

# =============================================================================
# CLASSIFICATION DIFFICULT√âS
# =============================================================================

def classify_difficulties(questions: List[Dict]) -> List[Dict]:
    """
    Classifie automatiquement les difficult√©s selon r√®gles.
    """
    print(f"\nüîç Classification automatique des difficult√©s...")
    
    for question in questions:
        # Si difficult√©s d√©j√† assign√©e, on la garde
        if not question.get('difficulty'):
            question['difficulty'] = auto_classify_difficulty(question)
        else:
            # Re-classification si incoh√©rent
            auto_diff = auto_classify_difficulty(question)
            question['difficulty'] = auto_diff
    
    # Stats distribution
    diff_counts = Counter(q.get('difficulty') for q in questions)
    total = len(questions)
    
    print(f"   Distribution apr√®s classification :")
    for diff in ['easy', 'medium', 'hard']:
        count = diff_counts.get(diff, 0)
        percent = count / total * 100 if total > 0 else 0
        target = TARGET_DISTRIBUTION.get(diff, 0) * 100
        print(f"     {diff:7s} : {count:4d} ({percent:5.1f}%) [cible: {target:.0f}%]")
    
    return questions

def balance_difficulties_by_module(questions: List[Dict]) -> List[Dict]:
    """
    R√©√©quilibre la distribution des difficult√©s par module si n√©cessaire.
    Cible: 40% easy / 40% medium / 20% hard
    """
    print(f"\n‚öñÔ∏è  R√©√©quilibrage difficult√©s par module...")
    
    # Groupe par module
    by_module = {}
    for question in questions:
        module_id = question.get('module_id', 'unknown')
        if module_id not in by_module:
            by_module[module_id] = []
        by_module[module_id].append(question)
    
    # Pour chaque module, v√©rifie distribution
    rebalanced_count = 0
    
    for module_id, module_questions in by_module.items():
        if len(module_questions) < 10:  # Skip petits modules
            continue
        
        # Distribution actuelle
        diff_counts = Counter(q['difficulty'] for q in module_questions)
        total = len(module_questions)
        
        for diff in ['easy', 'medium', 'hard']:
            current_pct = diff_counts.get(diff, 0) / total
            target_pct = TARGET_DISTRIBUTION[diff]
            
            # Si √©cart > 15%, on ajuste
            if abs(current_pct - target_pct) > 0.15:
                rebalanced_count += 1
                # Note: r√©√©quilibrage complet n√©cessiterait tri et r√©assignation
                # Pour v1, on log seulement
    
    if rebalanced_count > 0:
        print(f"   ‚ö†Ô∏è  {rebalanced_count} modules n√©cessitent r√©√©quilibrage (√©cart > 15%)")
        print(f"   Note: r√©√©quilibrage fin sera fait en Phase 5 si n√©cessaire")
    else:
        print(f"   ‚úì Distribution conforme pour tous les modules")
    
    return questions

# =============================================================================
# V√âRIFICATION EXHAUSTIVIT√â
# =============================================================================

def check_coverage(questions: List[Dict]) -> Dict:
    """
    V√©rifie que chaque chunk_id a g√©n√©r√© au moins 1 QCM valid√©.
    """
    print(f"\nüîç V√©rification exhaustivit√© corpus...")
    
    chunks_with_qcm = set(q.get('chunk_id') for q in questions if q.get('chunk_id'))
    
    print(f"   ‚úì {len(chunks_with_qcm)} chunks ont des QCM valid√©s")
    
    # Note: pour identifier chunks orphelins, il faudrait charger tous les modules
    # Pour v1, on log seulement le nombre de chunks couverts
    
    return {
        'chunks_covered': len(chunks_with_qcm),
        'coverage_percent': 0  # Sera calcul√© en Phase 5 avec coverage_report.py
    }

# =============================================================================
# MAIN
# =============================================================================

def main():
    parser = argparse.ArgumentParser(description="Validation finale et consolidation")
    parser.add_argument('--in', dest='input_file', required=True, help='Fichier questions scored')
    parser.add_argument('--out', required=True, help='Fichier validated.json de sortie')
    
    args = parser.parse_args()
    
    print("="*60)
    print("VALIDATION FINALE & CONSOLIDATION")
    print("="*60)
    
    # Charge questions
    print(f"\nüìÇ Chargement questions : {args.input_file}")
    with open(args.input_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    questions = data.get('questions', []) if isinstance(data, dict) else data
    print(f"   ‚úì {len(questions)} questions charg√©es")
    
    # √âtape 1: D√©duplication
    questions, nb_duplicates = deduplicate_questions(questions)
    
    # √âtape 2: Validation format
    questions, nb_invalid = validate_format(questions)
    
    # √âtape 3: Classification difficult√©s automatique
    questions = classify_difficulties(questions)
    
    # √âtape 4: R√©√©quilibrage par module
    questions = balance_difficulties_by_module(questions)
    
    # √âtape 5: V√©rification exhaustivit√©
    coverage_stats = check_coverage(questions)
    
    # Sauvegarde
    output_path = Path(args.out)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    output_data = {
        'validated_at': datetime.now().isoformat(),
        'total_questions': len(questions),
        'duplicates_removed': nb_duplicates,
        'invalid_format_removed': nb_invalid,
        'coverage': coverage_stats,
        'questions': questions
    }
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)
    
    print(f"\nüíæ Questions valid√©es sauvegard√©es : {args.out}")
    
    # R√©sum√© final
    print(f"\n{'='*60}")
    print(f"üìä R√âSUM√â VALIDATION FINALE")
    print(f"{'='*60}")
    print(f"Questions finales : {len(questions)}")
    print(f"Doublons supprim√©s : {nb_duplicates}")
    print(f"Format invalide : {nb_invalid}")
    print(f"Chunks couverts : {coverage_stats['chunks_covered']}")
    
    if len(questions) >= 2000:
        print(f"\n‚úÖ OBJECTIF ATTEINT : {len(questions)} ‚â• 2000 questions valid√©es")
    else:
        print(f"\n‚ö†Ô∏è  OBJECTIF NON ATTEINT : {len(questions)} < 2000 questions")
    
    print(f"\n{'='*60}")
    print(f"‚úÖ VALIDATION FINALE TERMIN√âE")
    print(f"{'='*60}")
    
    return 0

if __name__ == "__main__":
    exit(main())

