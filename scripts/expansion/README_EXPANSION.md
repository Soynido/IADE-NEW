# üöÄ Pipeline d'Expansion Massive - Phase 12

## üéØ Objectif

Multiplier le corpus par **√ó3-4** en passant de **165 QCM** √† **500+ QCM**.

**Ratio cible** : 3-5 QCM par page (vs 1.2 actuellement)

---

## üìä Vue d'ensemble

### Corpus actuel (v1.2.1)

- **165 QCM** valid√©s
- **98.2%** liens v√©rifi√©s
- **Score biom√©dical** : 0.932
- **Ratio** : ~1.2 QCM/page ‚ö†Ô∏è FAIBLE

### Corpus cible (v2.0)

- **500+ QCM** apr√®s expansion
- **3-5 QCM/page** (ratio optimal)
- **Qualit√© maintenue** (BioBERT ‚â• 0.4)
- **Z√©ro doublon** (d√©duplication fuzzy 85%)

---

## ‚öôÔ∏è Pipeline (4 √©tapes)

### 1Ô∏è‚É£ Extraction page par page (5 min)

**Script** : `extract_pages.py`

**Actions** :
- Extrait chaque page des 3 PDF
- Nettoie et normalise le texte
- Sauvegarde fichiers txt individuels
- G√©n√®re m√©tadonn√©es JSON

**Input** :
- `public/pdfs/*.pdf` (3 PDFs, 141 pages)

**Output** :
- `src/data/raw/pages/page_001.txt` ‚Üí `page_141.txt`
- `src/data/raw/pages_metadata.json`

---

### 2Ô∏è‚É£ G√©n√©ration massive (1-2h)

**Script** : `generate_massive.py`

**Actions** :
- G√©n√®re 3 QCM par page via Ollama Mistral
- Parall√©lisation (4 workers)
- Prompt strict (format JSON, qualit√© m√©dicale)
- Retry logic

**Options** :
```bash
# Toutes les pages
python scripts/expansion/generate_massive.py

# Batch sp√©cifique (recommand√© pour tests)
python scripts/expansion/generate_massive.py --range 0 50
python scripts/expansion/generate_massive.py --range 50 100
```

**Input** :
- `src/data/raw/pages/*.txt`
- `src/data/raw/pages_metadata.json`

**Output** :
- `src/data/questions/generated_massive.json` (~420 QCM)

---

### 3Ô∏è‚É£ Validation BioBERT (30 min)

**Script** : `validate_massive.py`

**Actions** :
- Calcule score biom√©dical pour chaque QCM
- Filtre selon seuil 0.4 (adapt√© pour volume)
- S√©pare valid√©s/rejet√©s

**Seuil** : 0.4 (vs 0.88 en raffinement)
- Plus permissif pour expansion
- Permet volume sans sacrifier qualit√©

**Input** :
- `src/data/questions/generated_massive.json`

**Output** :
- `src/data/questions/validated_massive.json` (~300-350 QCM)
- `src/data/questions/rejected_massive.json`

---

### 4Ô∏è‚É£ Fusion avec existant (5 min)

**Script** : `merge_with_existing.py`

**Actions** :
- Charge corpus v1.2.1 (165 QCM v√©rifi√©s)
- Charge nouveau corpus valid√©
- D√©tecte doublons (fuzzy matching 85%)
- Fusionne et sauvegarde

**D√©duplication** :
- Utilise `rapidfuzz.ratio`
- Seuil 85% de similarit√©
- Compare texte des questions

**Input** :
- `src/data/questions/compiled_verified.json` (v1.2.1)
- `src/data/questions/validated_massive.json`

**Output** :
- `src/data/questions/compiled_expanded.json` (v2.0)
- `src/data/questions/expansion_summary.txt`

---

## üöÄ Lancement

### Pipeline complet (recommand√©)

```bash
cd "/Users/valentingaludec/IADE NEW"
source venv/bin/activate
bash scripts/expansion/run_expansion.sh
```

### √âtape par √©tape

```bash
# 1. Extraction
python scripts/expansion/extract_pages.py

# 2. G√©n√©ration (batch ou full)
python scripts/expansion/generate_massive.py --range 0 50
python scripts/expansion/generate_massive.py --range 50 100
# ou
python scripts/expansion/generate_massive.py  # Toutes

# 3. Validation
python scripts/expansion/validate_massive.py

# 4. Fusion
python scripts/expansion/merge_with_existing.py
```

---

## üìä Estimations

| √âtape | Dur√©e | QCM |
|-------|-------|-----|
| Extraction | 5 min | - |
| G√©n√©ration | 1-2h | ~420 |
| Validation | 30 min | ~300-350 |
| Fusion | 5 min | +250-300 |
| **TOTAL** | **2-2.5h** | **465-565** |

**Gain attendu** : **√ó2.8-3.4** le corpus actuel

---

## üîß Options avanc√©es

### G√©n√©ration par batch

Pour √©viter timeout/crash sur g√©n√©ration longue :

```bash
# Batch 1 (pages 0-50)
python scripts/expansion/generate_massive.py --range 0 50

# Batch 2 (pages 50-100)
python scripts/expansion/generate_massive.py --range 50 100

# Batch 3 (pages 100-141)
python scripts/expansion/generate_massive.py --range 100 141
```

Les fichiers JSON s'accumulent, puis fusion finale.

### Redis/Upstash checkpoint (optionnel)

Si `UPSTASH_REDIS_REST_URL` est d√©fini dans `.env.local`, le syst√®me sauvegarde la progression :

```bash
# Check progression
redis-cli -u $UPSTASH_URL GET "phase12:progress"

# Reset si besoin
redis-cli -u $UPSTASH_URL DEL "phase12:progress"
```

---

## üìù Logs & Monitoring

Tous les logs sont centralis√©s dans `logs/pipeline.log` :

```bash
# Suivre en temps r√©el
tail -f logs/pipeline.log

# Voir historique
cat logs/pipeline.log
```

Format :
```
[2025-11-08 15:30:00] Phase 12 - Extraction START
[2025-11-08 15:35:12] Phase 12 - Extraction END: 141 pages
[2025-11-08 15:35:15] Phase 12 - G√©n√©ration START: 141 pages
[2025-11-08 17:12:43] Phase 12 - G√©n√©ration END: 387 QCM, 12 failed
[2025-11-08 17:13:00] Phase 12 - Validation START: 387 QCM
[2025-11-08 17:45:23] Phase 12 - Validation END: 312 validated, 75 rejected
[2025-11-08 17:45:30] Phase 12 - Fusion ‚úì 287 added, 452 total
```

---

## ‚úÖ Qualit√© garantie

### Validation multi-niveaux

1. **G√©n√©ration** : Prompt strict, format JSON valid√©
2. **BioBERT** : Seuil 0.4 (coh√©rence biom√©dicale)
3. **D√©duplication** : Fuzzy 85% (pas de doublons)
4. **H√©ritage** : 165 QCM v1.2.1 (d√©j√† v√©rifi√©s 98.2%)

### M√©triques attendues

- **Score biom√©dical moyen** : ~0.6-0.7 (nouveau corpus)
- **Taux de validation** : 70-80% (BioBERT 0.4)
- **Taux de duplication** : < 10%
- **QCM finaux** : 450-550

---

## üéØ Apr√®s l'expansion

### 1. Audit du nouveau corpus

```bash
python scripts/validation/audit_full_corpus.py
```

V√©rifie les liens CTA pour les nouveaux QCM.

### 2. R√©g√©n√©ration examens blancs

```bash
python scripts/ai_generation/exam_builder.py \
  --in src/data/questions/compiled_expanded.json \
  --out-dir public/data/exams
```

6 examens avec corpus √©largi.

### 3. D√©ploiement v2.0

```bash
python scripts/production/deploy_v2.0.py
npm run build
vercel --prod
gh release create v2.0 ...
```

---

## ‚ö†Ô∏è Recommandations

### Avant de lancer

- ‚úÖ V√©rifier qu'Ollama tourne : `ollama ps`
- ‚úÖ V√©rifier espace disque : ~500 MB libres
- ‚úÖ Tester v1.2.2 stable
- ‚úÖ Pr√©voir 2-3h de temps machine

### Pendant l'ex√©cution

- Monitorer : `tail -f logs/pipeline.log`
- Pas d'interruption pendant g√©n√©ration
- Ollama peut √™tre lent sur certaines pages complexes

### Apr√®s compl√©tion

- Auditer corpus expans√©
- Tester modes p√©dagogiques
- V√©rifier √©quilibre modules
- Valider avant d√©ploiement

---

## üîÑ Boucle d'am√©lioration continue

Une fois v2.0 d√©ploy√©e :

1. **Feedback utilisateur** : Bad/Good/Very Good (Redis)
2. **Analyse** : Identifier les QCM low-score
3. **Raffinement** : R√©g√©n√©rer les questions faibles
4. **Mise √† jour** : D√©ploiement v2.1, v2.2, etc.

---

**üéì Ce pipeline transforme IADE NEW en un syst√®me auto-g√©n√©ratif et √©volutif !**

