#!/usr/bin/env python3

"""
DÃ©tecte et regroupe les doublons de chunk_id dans compiled.json
Permet de prÃ©parer une fusion correcte (prÃ©serve toutes les variantes)
"""

import json
from collections import defaultdict
from pathlib import Path

INPUT = Path("src/data/questions/compiled.json")
OUTPUT = Path("src/data/questions/compiled_dedup.json")

with open(INPUT, "r") as f:
    data = json.load(f)

questions = data.get("questions", data)

# Regroupe par chunk_id
groups = defaultdict(list)
for q in questions:
    groups[q.get("chunk_id", "unknown")].append(q)

duplicates = {k: v for k, v in groups.items() if len(v) > 1}

print(f"ğŸ” {len(duplicates)} chunk_id ont plusieurs versions")
for cid, qs in list(duplicates.items())[:5]:
    print(f" - {cid}: {len(qs)} variantes")

# SÃ©lectionne la meilleure version selon rÃ¨gles simples
deduped = []
for cid, qs in groups.items():
    if len(qs) == 1:
        deduped.append(qs[0])
    else:
        # PrioritÃ© : version avec meilleur biomedical_score
        best = max(qs, key=lambda x: x.get("biomedical_score", 0))
        deduped.append(best)

data["questions"] = deduped
data["total_questions"] = len(deduped)

with open(OUTPUT, "w") as f:
    json.dump(data, f, ensure_ascii=False, indent=2)

print(f"\nâœ… DÃ©duplication terminÃ©e : {len(deduped)} questions conservÃ©es (unique chunk_id)")
print(f"ğŸ’¾ SauvegardÃ© dans : {OUTPUT}")

